{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0718 12:27:17.306177 140060682143552 deprecation_wrapper.py:119] From /home/vahe/anaconda3/envs/similarity/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(4096,), name='anchor')\n",
    "input2 = Input(shape=(4096,), name='positive')\n",
    "input3 = Input(shape=(4096,), name='negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 12:27:19.379912 140060682143552 deprecation_wrapper.py:119] From /home/vahe/anaconda3/envs/similarity/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shared_layer = Dense(100, name='shared')\n",
    "output1 = shared_layer(input1)\n",
    "output2 = shared_layer(input2)\n",
    "output3 = shared_layer(input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_vector = concatenate([output1, output2, output3], axis=-1, name='merged_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 12:27:25.853374 140060682143552 deprecation_wrapper.py:119] From /home/vahe/anaconda3/envs/similarity/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input1,input2,input3], outputs=merged_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_dummy, y_concatenated, margin=0.5):\n",
    "    total_length = y_concatenated.shape.as_list()[-1]\n",
    "    y_anchor = y_concatenated[:,:int(total_length*1/3)]\n",
    "    y_positive = y_concatenated[:,int(total_length*1/3):int(total_length*2/3)]\n",
    "    y_negative = y_concatenated[:,int(total_length*2/3):]\n",
    "    \n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(y_anchor-y_positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(y_anchor-y_negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+margin\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', loss=triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor (InputLayer)             (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive (InputLayer)           (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative (InputLayer)           (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared (Dense)                  (None, 100)          409700      anchor[0][0]                     \n",
      "                                                                 positive[0][0]                   \n",
      "                                                                 negative[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 300)          0           shared[0][0]                     \n",
      "                                                                 shared[1][0]                     \n",
      "                                                                 shared[2][0]                     \n",
      "==================================================================================================\n",
      "Total params: 409,700\n",
      "Trainable params: 409,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from keras.engine.network import Network\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.training_utils import collect_metrics\n",
    "from keras.engine.training_utils import check_array_length_consistency\n",
    "from keras.engine.training_utils import check_loss_and_target_compatibility\n",
    "from keras.engine.training_utils import standardize_class_weights\n",
    "from keras.engine.training_utils import standardize_input_data\n",
    "from keras.engine.training_utils import standardize_sample_weights\n",
    "from keras.engine.training_utils import standardize_weights\n",
    "from keras.engine.training_utils import weighted_masked_objective\n",
    "from keras.engine import training_arrays\n",
    "from keras.engine import training_generator\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics as metrics_module\n",
    "from keras.utils.generic_utils import slice_arrays\n",
    "from keras.utils.generic_utils import to_list\n",
    "from keras.utils.generic_utils import unpack_singleton\n",
    "from keras.legacy import interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "class MyModel(Model):\n",
    "    def compile1(self, optimizer,\n",
    "                loss=None,\n",
    "                metrics=None,\n",
    "                loss_weights=None,\n",
    "                sample_weight_mode=None,\n",
    "                weighted_metrics=None,\n",
    "                target_tensors=None,\n",
    "                **kwargs):\n",
    "        \"\"\"Configures the model for training.\n",
    "        # Arguments\n",
    "            optimizer: String (name of optimizer) or optimizer instance.\n",
    "                See [optimizers](/optimizers).\n",
    "            loss: String (name of objective function) or objective function.\n",
    "                See [losses](/losses).\n",
    "                If the model has multiple outputs, you can use a different loss\n",
    "                on each output by passing a dictionary or a list of losses.\n",
    "                The loss value that will be minimized by the model\n",
    "                will then be the sum of all individual losses.\n",
    "            metrics: List of metrics to be evaluated by the model\n",
    "                during training and testing.\n",
    "                Typically you will use `metrics=['accuracy']`.\n",
    "                To specify different metrics for different outputs of a\n",
    "                multi-output model, you could also pass a dictionary,\n",
    "                such as `metrics={'output_a': 'accuracy'}`.\n",
    "            loss_weights: Optional list or dictionary specifying scalar\n",
    "                coefficients (Python floats) to weight the loss contributions\n",
    "                of different model outputs.\n",
    "                The loss value that will be minimized by the model\n",
    "                will then be the *weighted sum* of all individual losses,\n",
    "                weighted by the `loss_weights` coefficients.\n",
    "                If a list, it is expected to have a 1:1 mapping\n",
    "                to the model's outputs. If a dict, it is expected to map\n",
    "                output names (strings) to scalar coefficients.\n",
    "            sample_weight_mode: If you need to do timestep-wise\n",
    "                sample weighting (2D weights), set this to `\"temporal\"`.\n",
    "                `None` defaults to sample-wise weights (1D).\n",
    "                If the model has multiple outputs, you can use a different\n",
    "                `sample_weight_mode` on each output by passing a\n",
    "                dictionary or a list of modes.\n",
    "            weighted_metrics: List of metrics to be evaluated and weighted\n",
    "                by sample_weight or class_weight during training and testing.\n",
    "            target_tensors: By default, Keras will create placeholders for the\n",
    "                model's target, which will be fed with the target data during\n",
    "                training. If instead you would like to use your own\n",
    "                target tensors (in turn, Keras will not expect external\n",
    "                Numpy data for these targets at training time), you\n",
    "                can specify them via the `target_tensors` argument. It can be\n",
    "                a single tensor (for a single-output model), a list of tensors,\n",
    "                or a dict mapping output names to target tensors.\n",
    "            **kwargs: When using the Theano/CNTK backends, these arguments\n",
    "                are passed into `K.function`.\n",
    "                When using the TensorFlow backend,\n",
    "                these arguments are passed into `tf.Session.run`.\n",
    "        # Raises\n",
    "            ValueError: In case of invalid arguments for\n",
    "                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizers.get(optimizer)\n",
    "        self.loss = loss or []\n",
    "        self.metrics = metrics or []\n",
    "        self.loss_weights = loss_weights\n",
    "        self.sample_weight_mode = sample_weight_mode\n",
    "        self.weighted_metrics = weighted_metrics\n",
    "\n",
    "        if not self.built:\n",
    "            # Model is not compilable because\n",
    "            # it does not know its number of inputs\n",
    "            # and outputs, nor their shapes and names.\n",
    "            # We will compile after the first\n",
    "            # time the model gets called on training data.\n",
    "            return\n",
    "        self._is_compiled = True\n",
    "\n",
    "        \n",
    "        loss_function = losses.get(loss)\n",
    "        loss_functions = [loss_function for _ in range(len(self.outputs))]\n",
    "        self.loss_functions = loss_functions\n",
    "        weighted_losses = [\n",
    "            weighted_masked_objective(fn) for fn in loss_functions]\n",
    "        skip_target_indices = []\n",
    "        skip_target_weighing_indices = []\n",
    "        self._feed_outputs = []\n",
    "        self._feed_output_names = []\n",
    "        self._feed_output_shapes = []\n",
    "        self._feed_loss_fns = []\n",
    "        for i in range(len(weighted_losses)):\n",
    "            if weighted_losses[i] is None:\n",
    "                skip_target_indices.append(i)\n",
    "                skip_target_weighing_indices.append(i)\n",
    "        # Prepare output masks.\n",
    "        masks = self.compute_mask(self.inputs, mask=None)\n",
    "        if masks is None:\n",
    "            masks = [None for _ in self.outputs]\n",
    "        masks = to_list(masks)\n",
    "        \n",
    "         # Prepare loss weights.\n",
    "        if loss_weights is None:\n",
    "            loss_weights_list = [1. for _ in range(len(self.outputs))]\n",
    "        elif isinstance(loss_weights, dict):\n",
    "            for name in loss_weights:\n",
    "                if name not in self.output_names:\n",
    "                    raise ValueError('Unknown entry in loss_weights '\n",
    "                                     'dictionary: \"' + name + '\". '\n",
    "                                     'Only expected the following keys: ' +\n",
    "                                     str(self.output_names))\n",
    "            loss_weights_list = []\n",
    "            for name in self.output_names:\n",
    "                loss_weights_list.append(loss_weights.get(name, 1.))\n",
    "        elif isinstance(loss_weights, list):\n",
    "            if len(loss_weights) != len(self.outputs):\n",
    "                raise ValueError('When passing a list as loss_weights, '\n",
    "                                 'it should have one entry per model output. '\n",
    "                                 'The model has ' + str(len(self.outputs)) +\n",
    "                                 ' outputs, but you passed loss_weights=' +\n",
    "                                 str(loss_weights))\n",
    "            loss_weights_list = loss_weights\n",
    "        else:\n",
    "            raise TypeError('Could not interpret loss_weights argument: ' +\n",
    "                            str(loss_weights) +\n",
    "                            ' - expected a list of dicts.')\n",
    "            \n",
    "        # Prepare targets of model.\n",
    "        self.targets = []\n",
    "        self._feed_targets = []\n",
    "#         if target_tensors is not None:\n",
    "#             if isinstance(target_tensors, list):\n",
    "#                 if len(target_tensors) != len(self.outputs):\n",
    "#                     raise ValueError(\n",
    "#                         'When passing a list as `target_tensors`, '\n",
    "#                         'it should have one entry per model output. '\n",
    "#                         'The model has ' + str(len(self.outputs)) +\n",
    "#                         ' outputs, but you passed target_tensors=' +\n",
    "#                         str(target_tensors))\n",
    "#             elif isinstance(target_tensors, dict):\n",
    "#                 for name in target_tensors:\n",
    "#                     if name not in self.output_names:\n",
    "#                         raise ValueError('Unknown entry in `target_tensors` '\n",
    "#                                          'dictionary: \"' + name + '\". '\n",
    "#                                          'Only expected the following keys: ' +\n",
    "#                                          str(self.output_names))\n",
    "#                 tmp_target_tensors = []\n",
    "#                 for name in self.output_names:\n",
    "#                     tmp_target_tensors.append(target_tensors.get(name, None))\n",
    "#                 target_tensors = tmp_target_tensors\n",
    "#             elif K.is_tensor(target_tensors):\n",
    "#                 if len(self.outputs) != 1:\n",
    "#                     raise ValueError('The model has ' + str(len(self.outputs)) +\n",
    "#                                      ' outputs, but you passed a single tensor as '\n",
    "#                                      '`target_tensors`. Expected a list or a dict '\n",
    "#                                      'of tensors.')\n",
    "#                 target_tensors = [target_tensors]\n",
    "#             else:\n",
    "#                 raise TypeError('Expected `target_tensors` to be a tensor, '\n",
    "#                                 'a list of tensors, or dict of tensors, but got:',\n",
    "#                                 target_tensors)\n",
    "        \n",
    "        for i in range(len(self.outputs)):\n",
    "            if i in skip_target_indices:\n",
    "                self.targets.append(None)\n",
    "            else:\n",
    "                shape = K.int_shape(self.outputs[i])\n",
    "                name = self.output_names[i]\n",
    "                if target_tensors is not None:\n",
    "                    target = target_tensors[i]\n",
    "                else:\n",
    "                    target = None\n",
    "                if target is None or K.is_placeholder(target):\n",
    "                    if target is None:\n",
    "                        target = K.placeholder(\n",
    "                            ndim=len(shape),\n",
    "                            name=name + '_target',\n",
    "                            sparse=K.is_sparse(self.outputs[i]),\n",
    "                            dtype=K.dtype(self.outputs[i]))\n",
    "                    self._feed_targets.append(target)\n",
    "                    self._feed_outputs.append(self.outputs[i])\n",
    "                    self._feed_output_names.append(name)\n",
    "                    self._feed_output_shapes.append(shape)\n",
    "                    self._feed_loss_fns.append(self.loss_functions[i])\n",
    "                else:\n",
    "                    skip_target_weighing_indices.append(i)\n",
    "                self.targets.append(target)\n",
    "\n",
    "        # Prepare sample weights.\n",
    "        sample_weights = []\n",
    "        sample_weight_modes = []\n",
    "        if isinstance(sample_weight_mode, dict):\n",
    "            for name in sample_weight_mode:\n",
    "                if name not in self.output_names:\n",
    "                    raise ValueError('Unknown entry in '\n",
    "                                     'sample_weight_mode dictionary: \"' +\n",
    "                                     name + '\". '\n",
    "                                     'Only expected the following keys: ' +\n",
    "                                     str(self.output_names))\n",
    "            for i, name in enumerate(self.output_names):\n",
    "                if i in skip_target_weighing_indices:\n",
    "                    weight = None\n",
    "                    sample_weight_modes.append(None)\n",
    "                else:\n",
    "                    if name not in sample_weight_mode:\n",
    "                        raise ValueError('Output \"' + name +\n",
    "                                         '\" missing from sample_weight_modes '\n",
    "                                         'dictionary')\n",
    "                    if sample_weight_mode.get(name) == 'temporal':\n",
    "                        weight = K.placeholder(ndim=2,\n",
    "                                               name=name + '_sample_weights')\n",
    "                        sample_weight_modes.append('temporal')\n",
    "                    else:\n",
    "                        weight = K.placeholder(ndim=1,\n",
    "                                               name=name + '_sample_weights')\n",
    "                        sample_weight_modes.append(None)\n",
    "                sample_weights.append(weight)\n",
    "        elif isinstance(sample_weight_mode, list):\n",
    "            if len(sample_weight_mode) != len(self.outputs):\n",
    "                raise ValueError('When passing a list as sample_weight_mode, '\n",
    "                                 'it should have one entry per model output. '\n",
    "                                 'The model has ' + str(len(self.outputs)) +\n",
    "                                 ' outputs, but you passed '\n",
    "                                 'sample_weight_mode=' +\n",
    "                                 str(sample_weight_mode))\n",
    "            for i in range(len(self.output_names)):\n",
    "                if i in skip_target_weighing_indices:\n",
    "                    weight = None\n",
    "                    sample_weight_modes.append(None)\n",
    "                else:\n",
    "                    mode = sample_weight_mode[i]\n",
    "                    name = self.output_names[i]\n",
    "                    if mode == 'temporal':\n",
    "                        weight = K.placeholder(ndim=2,\n",
    "                                               name=name + '_sample_weights')\n",
    "                        sample_weight_modes.append('temporal')\n",
    "                    else:\n",
    "                        weight = K.placeholder(ndim=1,\n",
    "                                               name=name + '_sample_weights')\n",
    "                        sample_weight_modes.append(None)\n",
    "                sample_weights.append(weight)\n",
    "        else:\n",
    "            for i, name in enumerate(self.output_names):\n",
    "                if i in skip_target_weighing_indices:\n",
    "                    sample_weight_modes.append(None)\n",
    "                    sample_weights.append(None)\n",
    "                else:\n",
    "                    if sample_weight_mode == 'temporal':\n",
    "                        sample_weights.append(\n",
    "                            K.placeholder(ndim=2,\n",
    "                                          name=name + '_sample_weights'))\n",
    "                        sample_weight_modes.append('temporal')\n",
    "                    else:\n",
    "                        sample_weights.append(\n",
    "                            K.placeholder(ndim=1,\n",
    "                                          name=name + '_sample_weights'))\n",
    "                        sample_weight_modes.append(None)\n",
    "        self.sample_weight_modes = sample_weight_modes\n",
    "        self._feed_sample_weight_modes = []\n",
    "        for i in range(len(self.outputs)):\n",
    "            if i not in skip_target_weighing_indices:\n",
    "                self._feed_sample_weight_modes.append(\n",
    "                    self.sample_weight_modes[i])\n",
    "        \n",
    "        # Prepare metrics.\n",
    "        self.metrics_names = ['loss']\n",
    "        self.metrics_tensors = []\n",
    "\n",
    "        # Compute total loss.\n",
    "        total_loss = None\n",
    "        with K.name_scope('loss'):\n",
    "            for i in range(len(self.outputs)):\n",
    "                if i in skip_target_indices:\n",
    "                    continue\n",
    "                y_true = self.targets[i]\n",
    "                y_pred = self.outputs[i]\n",
    "                \n",
    "                weighted_loss = weighted_losses[i]\n",
    "                sample_weight = sample_weights[i]\n",
    "                mask = masks[i]\n",
    "                loss_weight = loss_weights_list[i]\n",
    "                \n",
    "                with K.name_scope(self.output_names[i] + '_loss'):\n",
    "                    output_loss = weighted_loss(y_true, y_pred,\n",
    "                                                sample_weight, mask)\n",
    "                   \n",
    "                \n",
    "                if len(self.outputs) > 1:\n",
    "                    self.metrics_tensors.append(output_loss)\n",
    "                    self.metrics_names.append(self.output_names[i] + '_loss')\n",
    "                if total_loss is None:\n",
    "                    total_loss = loss_weight * output_loss\n",
    "                else:\n",
    "                    total_loss += loss_weight * output_loss\n",
    "            if total_loss is None:\n",
    "                if not self.losses:\n",
    "                    raise ValueError('The model cannot be compiled '\n",
    "                                     'because it has no loss to optimize.')\n",
    "                else:\n",
    "                    total_loss = 0.\n",
    "\n",
    "            # Add regularization penalties\n",
    "            # and other layer-specific losses.\n",
    "            for loss_tensor in self.losses:\n",
    "                total_loss += loss_tensor\n",
    "        \n",
    "        \n",
    "        # List of same size as output_names.\n",
    "        # contains tuples (metrics for output, names of metrics).\n",
    "        nested_metrics = collect_metrics(metrics, self.output_names)\n",
    "        nested_weighted_metrics = collect_metrics(weighted_metrics,\n",
    "                                                  self.output_names)\n",
    "        self.metrics_updates = []\n",
    "        self.stateful_metric_names = []\n",
    "        self.stateful_metric_functions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MyModel(inputs=[input1,input2,input3], outputs=merged_vector)\n",
    "model1.compile1(optimizer='SGD', loss=triplet_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
